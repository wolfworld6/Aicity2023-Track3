dataset_name: aicity
devices: ['cuda:0']
train_split: ['training']
val_split: ['validation']
dataset: {
  # json_file: ./data/aicity/annotations/aicity_track3_v3.json,
  # json_file: ./data/aicity/annotations/track3_Rearview.json,
  # json_file: ./data/aicity/annotations/track3_Rearview_Dashboard_A1-train_A2-val.json,
  # json_file: ./data/aicity/annotations/track3_Rearview_A1-train_A1-val.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1-train_A1-val.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1-train_A2-val_delete0.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1-train_A2Pre-val.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1-train_A2_Self_and_Pre-val.json,
  # json_file: ./data/aicity/annotations/track3_Rearview_A1-Alltraining.json,
  # json_file: ./data/aicity/annotations/track3_Rearview-Dashboard_A1-Alltraining.json,
  # json_file: ./data/aicity/annotations/track3_Rearview+Dashboard_A1-train_A1-val.json,
  # json_file: ./data/aicity/annotations/track3_Rearview+Dashboard_A1-train_A1-val_v2.json,
  # json_file: ./data/aicity/annotations/track3_Rearview.json,
  json_file: /mnt/home/Temporal-Action-Localization-Relevant/aicity_track3/preprocess/track3_only_Rearview_A1-train_A2-val-nullAnno.json,
  # json_file: ./data/aicity/annotations/track3_Dashboard.json,
  # json_file: ./data/aicity/annotations/track3_Right_side_window.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1_alltrain.json,
  # json_file: ./data/aicity/annotations/track3_only_Dashboard_A1_alltrain.json,
  # json_file: ./data/aicity/annotations/track3_only_Rearview_A1-train_A2_Pre7371-val.json,
  # json_file: ./data/aicity/annotations/track3_only_Right_side_window_A1_alltrain.json,
  # feat_folder: ./data/aicity/trained_features/features_UnifV2_clip400+sthv2_3modelTrained_crop_A1A2, 
  # feat_folder: ./data/aicity/v1_features/features_unifv2_clip400+sthv2_SingleTrained_224_A1A2, 
  # feat_folder: ./data/aicity/trained_features/features_hybrid_k700_track3_fine_pred_A1A2,
  # feat_folder: ./data/aicity/trained_features/features_vmae_vitHK400_trainedAIcityA1_1280+16_A1A2,
  # feat_folder: ./data/aicity/trained_features/features_UnifV2_clip400+sthv2_AiCityTrained_crop_A1A2,
  # feat_folder: ./data/aicity/trained_features/features_videomae_vitHK400_3modelAIcityA1_1280+16_personOnly_A1A2, 
  feat_folder:  /mnt/home/Temporal-Action-Localization-Relevant/TAL_track3_self/features/hybrid_35,
  # feat_folder: ./data/aicity/trained_features/features_videomae_vitHK400_s448_1280_16_personOnly_rear_e63_loss16_A1A2, 
  # feat_folder: ./data/aicity/trained_features/features_videomae_vitHInternK400_s448_1280_16_personOnly_rear_e95_loss131_A1A2, 
  # feat_folder: ./data/aicity/trained_features/features_hybrid_k700_vitl_track3_crop_pred_A1A2,
  # feat_folder: ./data/aicity/trained_features/features_ego4d_verb_vitl_track3_crop_pred_A1A2,
  # feat_folder: ./data/aicity/trained_features/features_hybrid_k700_vitl_track3_crop_pred_e35_A1A2,
  file_prefix: ~,
  file_ext: .npz,
  num_classes: 16,
  # num_classes: 15,
  input_dim: 1024,
  # input_dim: 1280,
  # input_dim: 1536,
  # input_dim: 2304,
  # input_dim: 3072,
  # input_dim: 4224,
  # input_dim: 2048,
  # input_dim: 9216,
  # feat_stride: 16,
  feat_stride: 16,
  num_frames: 32,
  default_fps: 30,
  trunc_thresh: 0.3,
  crop_ratio: [0.9, 1.0],
  # max_seq_len: 256,
  max_seq_len: 2048,
  # max_seq_len: 1024,
  feats_concat: False,
}
model: {
  regression_range: [[0, 4], [2, 8], [4, 16], [8, 32], [16, 64], [32, 10000]],
  # regression_range: [[0, 8], [2, 16], [4, 32], [8, 64], [16, 128], [32, 10000]],
  # regression_range: [[0, 8], [4, 16], [8, 32], [16, 64], [32, 128], [64, 10000]],
  # regression_range: [
  #   [0, 4], 
  #   [2, 8], 
  #   [4, 16], 
  #   [8, 32], 
  #   [16, 64], 
  #   [32, 128], 
  #   [64, 256],
  #   [128, 512],
  #   [256, 1024],
  #   [512, 2048],
  #   [1024, 10000]          # stride 1024
  # ],
  # regression_range: [
  #   [0, 16], 
  #   [16, 32], 
  #   [32, 64], 
  #   [64, 128],
  #   [128, 256],
  #   [256, 10000]          # stride 1024
  # ],
  # backbone_arch: [2, 2, 10],
  fpn_type: identity,
  # fpn_type: fpn,
  n_head: 4,
  # n_head: 8,
  channel_att_sride: 2,
  embd_dim: 512,
  fpn_dim: 512,
  head_dim: 512,
  # embd_dim: 1024,
  # fpn_dim: 1024,
  # head_dim: 1024,
  embd_kernel_size: 3,
  max_buffer_len_factor: 4.0,
  # embd_kernel_size: 7,
  # max_buffer_len_factor: 8.0,
  n_mha_win_size: 9,
  # n_mha_win_size: 19,
  # n_mha_win_size: 13,
  use_abs_pe: False,
  use_rel_pe: False,
}
opt: {
  # type: AdamW, # SGD or AdamW
  # learning_rate: 0.0001,
  learning_rate: 0.001,
  # epochs: 35,
  epochs: 40,
  # epochs: 15,
  # epochs: 30,
  weight_decay: 0.05,
}
loader: {
  batch_size: 1,
  num_workers: 8,
}
train_cfg: {
  init_loss_norm: 250,
  # loss_weight: 0.5,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  # center_sample_radius: 2.5,
  # label_smoothing:  0.25,
}
test_cfg: {
  # pre_nms_topk: 800,
  # max_seg_num: 400,
  pre_nms_topk: 5000,
  # max_seg_num: 2304,
  max_seg_num: 2048,
  # max_seg_num: 1024,
  # max_seg_num: 2000,
  # max_seg_num: 256,
  min_score: 0.001,
  nms_sigma : 0.25,
  multiclass_nms: True
  # ext_score_file: ./data/aicity/annotations/cuhk_val_simp_share.json
  # ext_score_file: ./data/aicity/features_unifv2_clip400+sthv2_SingleTrained_224_A1A2/
}
output_folder: ./ckpt_crop_Rear_hybrid/
